{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics and Cartesian Reconstructions\n",
    "Here we are going to have a look at a few basics of MRpro and reconstruct data acquired with a Cartesian sampling pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this notebook we are going to explore the MRpro KData object and the included header parameters. We will then use a FFT-operator in order to reconstruct data acquired with a Cartesian sampling scheme. Finally we will try to reconstruct data acquired on a Cartesian grid but with partial echo and partial Fourier acceleration.\n",
    "\n",
    "Run this notebook in Google colab: \n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/PTB-MR/mrpro_utrecht_workshop_2024/blob/main/solution_basics_and_cartesian_reconstruction.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install MRpro and download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MRpro\n",
    "!pip install git+https://github.com/PTB-MR/mrpro.git#egg=mrpro[notebook]\n",
    "import mrpro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the raw data from zenodo\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import zenodo_get\n",
    "\n",
    "data_folder = Path(tempfile.mkdtemp())\n",
    "dataset = '14173489'\n",
    "zenodo_get.zenodo_get([dataset, '-r', 5, '-o', data_folder])  # r: retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the downloaded files\n",
    "from os import listdir\n",
    "for f in listdir(data_folder):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have three different scans obtained from the same object with the same FOV and resolution:\n",
    "\n",
    "- cart_t1.mrd is a fully sampled Cartesian acquisition\n",
    "\n",
    "- cart_t1_partial_echo_partial_fourier.mrd is accelerated using partial echo and partial Fourier\n",
    "\n",
    "- cart_t1_msense_integraded.mrd is acclerated using regular undersampling and self-calibrated SENSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in raw data and explore header\n",
    "\n",
    "To read in a ISMRMRD raw data file we can simply pass on the file name to a KData object. In addition we also have to provide information about the trajectory. In MRpro this is done using trajectory calculators, which are functions that calculate the trajectory based on the acquisition information and additional parameters provided to the calculators (e.g. the angular step for a radial acquisition). In this case we have a Cartesian acquisition so we only need to provide a Cartesian trajectory calculator without any further parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdata = mrpro.data.KData.from_file(data_folder / Path('cart_t1.mrd'), mrpro.data.traj_calculators.KTrajectoryCartesian())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can explore this data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with simply calling print(kdata)\n",
    "print(kdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also have a look at the content of the header\n",
    "print(kdata.header.acq_info.position[0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction of fully sampled acquisition\n",
    "\n",
    "We have got a fully sampled Cartesian acquisition so we know we can use a Fast Fourier Transform (FFT) to reconstruction the data. Let's create an FFT-operator and apply it to kdata. Here it is important to note that all MRpro operators work on PyTorch tensors and not on the MRpro objects directly. Therefore we have to call the operator on kdata.data. One other important feature of MRpro operators is that the always return a tuple of length 1 of PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_op = mrpro.operators.FastFourierOp(dim=(-2,-1))\n",
    "idat = fft_op.adjoint(kdata.data)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the shape of the obtained tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(idat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the second dimension which is the coil dimension is 16, so we still have a coil resolved dataset. We can use a simply root-sum-of-squares approach to combine them into one. Later we will do something a bit more sophisticated. We can also see that the x-dimension is 512. This is because in MRI we commonly oversample the readout direction by a factor 2 leading to a FOV twice as large as we actually need. We can either remove this oversampling along the readout direction or we can simply tell the FFT-operator to remove it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_op = mrpro.operators.FastFourierOp(dim=(-2,-1), recon_matrix=kdata.header.recon_matrix, encoding_matrix=kdata.header.encoding_matrix)\n",
    "idat = fft_op.adjoint(kdata.data)[0]\n",
    "print(idat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an image which is 256 x 256 voxel as we would expect. Let's combine the data from the different receiver coils using root-sum-of-squares and then display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "idat = torch.sqrt(torch.sum(idat**2, dim=1)).abs()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.imshow(idat[0,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction of acquisition with partial echo and partial Fourier\n",
    "\n",
    "Great! That was very easy so let's try to reconstruct the next dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdata_pe_pf = mrpro.data.KData.from_file(data_folder / Path('cart_t1_partial_echo_partial_fourier.mrd'), mrpro.data.traj_calculators.KTrajectoryCartesian())\n",
    "fft_op = mrpro.operators.FastFourierOp(dim=(-2,-1), recon_matrix=kdata.header.recon_matrix, encoding_matrix=kdata.header.encoding_matrix)\n",
    "idat_pe_pf = fft_op.adjoint(kdata_pe_pf.data)[0]\n",
    "idat_pe_pf = torch.sqrt(torch.sum(idat_pe_pf**2, dim=1)).abs()\n",
    "\n",
    "fig, ax = plt.subplots(1,2, squeeze=False)\n",
    "ax[0,0].imshow(idat[0,0])\n",
    "ax[0,1].imshow(idat_pe_pf[0,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well we get an image out but when we compare it to the previous result it seems the head as shrunk. As this is not very likely there is probably a mistake in our reconstruction. \n",
    "\n",
    "Alright let's take a step back and have a look at the trajectory of both scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kdata.traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the trajectory consists of a kz, ky and kx part. Kx and ky only vary along a single dimension. The reason for this is that we try to save the trajectory in the most efficient way in MRpro. If we want to get the fully trajectory as a tensor we can call as_tensor()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(kdata.traj.as_tensor()[2,0,0,:,:].flatten(), kdata.traj.as_tensor()[1,0,0,:,:].flatten(), 'ob')\n",
    "plt.plot(kdata_pe_pf.traj.as_tensor()[2,0,0,:,:].flatten(), kdata_pe_pf.traj.as_tensor()[1,0,0,:,:].flatten(), '+r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for the fully sampled acquisition the k-space is covered symmetrically from -256 to 255 along the readout direction and from -128 to 127 along the phase encoding direction. For the acquisition with partial Fourier and partial echo acceleration this is of course not the case and the k-space is asymetrical. \n",
    "\n",
    "Our FFT-operator does not know about this and simply assumes that the acquisition is symmetric and any difference between encoding and recon matrix need to be zero-padded symmetrically.\n",
    "\n",
    "To take the asymetric acquisition into account and sort the data correctly into a matrix where we can apply the FFT-operator to, we have got the CartesianSamplingOp in MRpro. This operator calculates a sorting index based on the k-space trajectory and the dimensions of the encoding k-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_sampling_op = mrpro.operators.CartesianSamplingOp(kdata_pe_pf.header.encoding_matrix, kdata_pe_pf.traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can first apply the CartesianSamplingOp and then call the FFT-operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idat_pe_pf = fft_op.adjoint(cart_sampling_op.adjoint(kdata_pe_pf.data)[0])[0]\n",
    "idat_pe_pf = torch.sqrt(torch.sum(idat_pe_pf**2, dim=1)).abs()\n",
    "\n",
    "fig, ax = plt.subplots(1,2, squeeze=False)\n",
    "ax[0,0].imshow(idat[0,0])\n",
    "ax[0,1].imshow(idat_pe_pf[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila! Now we get the same brains with the same size. But hang on a second - there is still something which looks a bit funny. In the bottom left hand corner it seems that there is a \"hole\" in the brain. This should probably not be there. \n",
    "\n",
    "The reason for this is, that we simply combined the data from the different coils using a root-sum-of-squares approach. This was easy but not what we should do. Commonly coil sensitivity maps are calculated and they are then used to combine the data from the different coils. In MRpro this is done by calculating coil sensitivity data and then creating a SensitivityOp to combine the data after image reconstruction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different option of how to calculate coil sensitivity maps from image data of the different coils. Here we are going to use the Walsh-method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate coil sensitivity maps\n",
    "idat_pe_pf = fft_op.adjoint(cart_sampling_op.adjoint(kdata_pe_pf.data)[0])[0]\n",
    "# This algorithms is designed to calculate coil sensitivity maps for each other dimension. \n",
    "csm_data = mrpro.algorithms.csm.walsh(idat_pe_pf[0,...], smoothing_width=5)[None,...]\n",
    "\n",
    "# Create SensitivityOp\n",
    "csm_op = mrpro.operators.SensitivityOp(csm_data)\n",
    "\n",
    "# Reconstruct coil-combined image\n",
    "idat_pe_pf = csm_op.adjoint(fft_op.adjoint(cart_sampling_op.adjoint(kdata_pe_pf.data)[0])[0])[0].abs()\n",
    "\n",
    "fig, ax = plt.subplots(1,2, squeeze=False)\n",
    "ax[0,0].imshow(idat[0,0])\n",
    "ax[0,1].imshow(idat_pe_pf[0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we got an image without any \"holes\"! \n",
    "\n",
    "When we reconstructed the image we called the adjoint method of several different operators one after the other. That was a bit cumbersome. To make our life easier we can combine the operators directly and then call the adjoint of the composite operator. We have to keep in mind that we have to put them in the order of the forward method of the operators. By calling the adjoint, the order will be automatically reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create composite operator\n",
    "acq_op = cart_sampling_op @ fft_op @ csm_op \n",
    "idat_pe_pf = acq_op.adjoint(kdata_pe_pf.data)[0].abs()\n",
    "\n",
    "fig, ax = plt.subplots(1,2, squeeze=False)\n",
    "ax[0,0].imshow(idat[0,0])\n",
    "ax[0,1].imshow(idat_pe_pf[0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have got now a nice looking image, it was a bit cumbersome to create it. We had to define several different operators and chain them together. Would we nice if this could be done automatically....\n",
    "\n",
    "That is why we also included some top-level reconstruction algorithms. The reconstruction above we simply call DirectReconstruction. A DirectReconstruction object can be directly created from the information in the KData object.\n",
    "\n",
    "Reconstruction algorithms operator on the data objects of MRpro, i.e. the input is a KData object and the output is a IData object. To visualise this we need the tensor content of the IData object which can be obtained by calling .rss()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_recon_pe_pf = mrpro.algorithms.reconstruction.DirectReconstruction(kdata_pe_pf)\n",
    "idat_pe_pf = direct_recon_pe_pf(kdata_pe_pf)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, squeeze=False)\n",
    "ax[0,0].imshow(idat[0,0])\n",
    "ax[0,1].imshow(idat_pe_pf.rss()[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much simpler and all of the magic is done in the background and we don't have to worry about it. Let's try it on the undersampled dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction of undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdata_us = mrpro.data.KData.from_file(data_folder / Path('cart_t1_msense_integrated.mrd'), mrpro.data.traj_calculators.KTrajectoryCartesian())\n",
    "direct_recon_us = mrpro.algorithms.reconstruction.DirectReconstruction(kdata_us)\n",
    "idat_us = direct_recon_us(kdata_us)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, squeeze=False)\n",
    "ax[0,0].imshow(idat[0,0])\n",
    "ax[0,1].imshow(idat_us.rss()[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected we can see undersampling artefacts in the image. In order to get rid of them we can use an iterative SENSE algorithm. Of course for this regularly undersampled we could also use Cartesian SENSE unfolding but in MRpro we don't have that. \n",
    "\n",
    "Similary to the DirectReconstruction we can create an IterativeSENSEReconstruction and apply it to the undersampled KData. Give it a try and see if you can remove the undersampling artefacts. \n",
    "\n",
    "One important thing to keep in mind is, that this only works if the coil maps which we use, do not have any undersampling artefacts. Commonly we would get them from a fully sampled self-calibration reference lines in the centre of k-space or a separate coil sensitivity scan. Here we are going to cheat a bit and simply use the coil sensitivity maps from the fully sampled or the data with partial echo and partial Fourier. You can get the CsmData which is needed for the IterativeSENSEReconstruction by calling e.g. direct_recon_pe_pf.csm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdata_us = mrpro.data.KData.from_file(data_folder / Path('cart_t1_msense_integrated.mrd'), mrpro.data.traj_calculators.KTrajectoryCartesian())\n",
    "it_sense_recon = mrpro.algorithms.reconstruction.IterativeSENSEReconstruction(kdata_us, csm=direct_recon_pe_pf.csm)\n",
    "idat_us = it_sense_recon(kdata_us)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, squeeze=False)\n",
    "ax[0,0].imshow(idat[0,0])\n",
    "ax[0,1].imshow(idat_us.rss()[0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
